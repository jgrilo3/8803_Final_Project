{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ECE 8803 Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from dataloader import OCTDataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "root = os.getcwd()\n",
    "train = os.path.join(root, \"df_prime_train.csv\")\n",
    "test = os.path.join(root, \"df_prime_test.csv\")\n",
    "\n",
    "\n",
    "\n",
    "LABELS_SEVERITY = {35: 0,\n",
    "                   43: 0,\n",
    "                   47: 1,\n",
    "                   53: 1,\n",
    "                   61: 2,\n",
    "                   65: 2,\n",
    "                   71: 2,\n",
    "                   85: 2}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''Obtain Dataset Images'''\n",
    "\n",
    "\n",
    "mean = (.1706)\n",
    "std = (.2112)\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "args = 'C:/Users/jgril/Documents/GitHub/8803_Final_Project'\n",
    "image_trainset = OCTDataset(args, 'train', transform=transform)\n",
    "image_testset = OCTDataset(args, 'test', transform=transform)\n",
    "\n",
    "\n",
    "print(\"loading data\")\n",
    "\n",
    "images_train = []\n",
    "labels_train = []\n",
    "for i in range(len(image_trainset)):\n",
    "    image,label = image_trainset.__getitem__(i)\n",
    "    images_train.append(image.flatten())\n",
    "    labels_train.append(label)\n",
    "\n",
    "images_test = []\n",
    "labels_test = []\n",
    "for i in range(len(image_testset)):\n",
    "    image,label = image_trainset.__getitem__(i)\n",
    "    images_test.append(image.flatten())\n",
    "    labels_test.append(label)\n",
    "\n",
    "print(\"data loaded\")\n",
    "\n",
    "'''Meta Train Data'''\n",
    "meta_trainset = pd.read_csv(train).dropna()\n",
    "meta_testset = pd.read_csv(test).dropna()\n",
    "\n",
    "train = os.path.join(root, \"df_prime_train.csv\")\n",
    "test = os.path.join(root, \"df_prime_test.csv\")\n",
    "\n",
    "meta_X_train = meta_trainset[['Age', 'Gender', 'Race', \"Diabetes_Type\", \"Diabetes_Years\", \"BMI\", \"BCVA\", \"CST\", \"Leakage_Index\"]].to_numpy()\n",
    "meta_Y_train = meta_trainset[[\"DRSS\"]].to_numpy()\n",
    "y = []\n",
    "for i in range(meta_Y_train.shape[0]):\n",
    "    y.append(LABELS_SEVERITY[int(meta_Y_train[i])])\n",
    "\n",
    "meta_Y_train = np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "'''Meta Test Data'''\n",
    "meta_X_test = meta_testset[['Age', 'Gender', 'Race', \"Diabetes_Type\", \"Diabetes_Years\", \"BMI\", \"BCVA\", \"CST\", \"Leakage_Index\"]].to_numpy()\n",
    "meta_Y_test = meta_testset[[\"DRSS\"]].to_numpy() \n",
    "y = []\n",
    "for i in range(meta_Y_test.shape[0]):\n",
    "    y.append(LABELS_SEVERITY[int(meta_Y_test[i])])\n",
    "\n",
    "Y_test = np.array(y)\n",
    "\n",
    "\n",
    "#print(meta_X_train)\n",
    "#print(meta_Y_train)\n",
    "#print(meta_X_test)\n",
    "#print(meta_Y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "(tensor([[[-0.6592, -0.7149, -0.6778,  ..., -0.8078, -0.8078, -0.8078],\n",
      "         [-0.1950, -0.4550, -0.3621,  ..., -0.8078, -0.8078, -0.8078],\n",
      "         [-0.4735, -0.6221, -0.6407,  ..., -0.8078, -0.8078, -0.8078],\n",
      "         ...,\n",
      "         [-0.6221, -0.7706, -0.7892,  ..., -0.8078, -0.8078, -0.8078],\n",
      "         [-0.7335, -0.7892, -0.7706,  ..., -0.8078, -0.8078, -0.8078],\n",
      "         [-0.8078, -0.7892, -0.7706,  ..., -0.8078, -0.8078, -0.8078]]]), 2)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jgril\\Documents\\GitHub\\8803_Final_Project\\8803FinalProject.ipynb Cell 4\u001b[0m in \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jgril/Documents/GitHub/8803_Final_Project/8803FinalProject.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(image_trainset[\u001b[39m0\u001b[39m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jgril/Documents/GitHub/8803_Final_Project/8803FinalProject.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(image_trainset[\u001b[39m0\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jgril/Documents/GitHub/8803_Final_Project/8803FinalProject.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mnumpy(images_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jgril/Documents/GitHub/8803_Final_Project/8803FinalProject.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnumpy(labels_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jgril/Documents/GitHub/8803_Final_Project/8803FinalProject.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m X_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnumpy(images_test)\n",
      "File \u001b[1;32mc:\\Users\\jgril\\miniconda3\\lib\\site-packages\\numpy\\__init__.py:311\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m Tester\n\u001b[0;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m Tester\n\u001b[1;32m--> 311\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(type(image_trainset[0]))\n",
    "print(image_trainset[0])\n",
    "X_train = np.numpy(images_train)\n",
    "y_train = np.numpy(labels_train)\n",
    "\n",
    "X_test = np.numpy(images_test)\n",
    "y_test = np.numpy(labels_test)\n",
    "\n",
    "\n",
    "# train a Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the classifier on the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 189\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m    187\u001b[0m svm \u001b[39m=\u001b[39m SVM()\n\u001b[1;32m--> 189\u001b[0m w, b, losses \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39;49mfit(X_train, Y_train)\n\u001b[0;32m    191\u001b[0m prediction \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m    193\u001b[0m \u001b[39m# Loss value\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [16], line 107\u001b[0m, in \u001b[0;36mSVM.fit\u001b[1;34m(self, X, Y, batch_size, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     95\u001b[0m x \u001b[39m=\u001b[39m ids[j]\n\u001b[0;32m     97\u001b[0m \u001b[39m## question ii\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m# calculating the gradients\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39m# data sample.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39m#max(0,1−yi(w⊤xi−b))\u001b[39;00m\n\u001b[1;32m--> 107\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m Y[x]\u001b[39m*\u001b[39m(X[x] \u001b[39m@\u001b[39;49m w\u001b[39m.\u001b[39;49mT \u001b[39m+\u001b[39;49m b) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m    108\u001b[0m   gradw \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m w \u001b[39m+\u001b[39m c \u001b[39m*\u001b[39m \u001b[39m-\u001b[39mY[x] \u001b[39m*\u001b[39m X[x]\n\u001b[0;32m    109\u001b[0m   gradb \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m c \u001b[39m*\u001b[39m \u001b[39m-\u001b[39mY[x] \u001b[39m*\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load iris dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test \n",
    " = images_train.numpy()\n",
    "y = labels_train\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "\n",
    "# Create SVM classifier\n",
    "clf = svm.SVC(kernel='linear', C=1, decision_function_shape='ovr')\n",
    "\n",
    "# Train classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f53be5b945d9bd707dfb463269b5f5206ccedac637d039afb7a68ece5d290f2d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
